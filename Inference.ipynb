{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-24T14:35:48.541778Z",
     "start_time": "2024-04-24T14:35:43.960942Z"
    }
   },
   "source": [
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRangePercentiles,\n",
    "    ScaleIntensityRange,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Invertd,\n",
    "    EnsureTyped,\n",
    "    NormalizeIntensityd,\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.losses import GeneralizedDiceLoss\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "print_config()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.4.dev2415\n",
      "Numpy version: 1.26.4\n",
      "Pytorch version: 2.2.1\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 189d1865c1b5b228b9d9e5e95ed40969eda7badc\n",
      "MONAI __file__: C:\\Users\\<username>\\.conda\\envs\\nnUNet\\Lib\\site-packages\\monai\\__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.11\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 5.2.1\n",
      "scikit-image version: 0.22.0\n",
      "scipy version: 1.12.0\n",
      "Pillow version: 10.2.0\n",
      "Tensorboard version: 2.16.2\n",
      "gdown version: 4.7.3\n",
      "TorchVision version: 0.17.1\n",
      "tqdm version: 4.66.2\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.8\n",
      "pandas version: 2.2.1\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T15:21:55.381321Z",
     "start_time": "2024-04-24T15:21:55.344114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "directory = \"demo_data2\"\n",
    "test_images = sorted(glob.glob(os.path.join(directory, \"imagesTs\", \"*.nii.gz\")))\n",
    "test_data = [{\"image\": image} for image in test_images]\n",
    "test_data"
   ],
   "id": "ff001680e5e58827",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'image': 'demo_data2\\\\imagesTs\\\\case_00210_0000.nii.gz'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T15:22:27.591472Z",
     "start_time": "2024-04-24T15:22:27.583833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "keys = \"image\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "test_org_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=keys),\n",
    "        EnsureChannelFirstd(keys=keys),\n",
    "        EnsureTyped(keys=keys),\n",
    "        Spacingd(keys=keys, pixdim=(1, 0.78, 0.78), mode=\"bilinear\"),\n",
    "        Orientationd(keys=keys, axcodes=\"RAS\"),\n",
    "        NormalizeIntensityd(keys=\"image\"),\n",
    "        CropForegroundd(keys=keys, source_key=\"image\"),\n",
    "    ]\n",
    ")\n",
    "test_org_ds = Dataset(data=test_data, transform=test_org_transforms)\n",
    "\n",
    "test_org_loader = DataLoader(test_org_ds, batch_size=1, num_workers=4)\n",
    "post_transforms = Compose(\n",
    "    [\n",
    "        Invertd(\n",
    "            keys=\"pred\",\n",
    "            transform=test_org_transforms,\n",
    "            orig_keys=\"image\",\n",
    "            meta_keys=\"pred_meta_dict\",\n",
    "            orig_meta_keys=\"image_meta_dict\",\n",
    "            meta_key_postfix=\"meta_dict\",\n",
    "            nearest_interp=False,\n",
    "            to_tensor=True,\n",
    "        ),\n",
    "        AsDiscreted(keys=\"pred\", argmax=True, to_onehot=3),\n",
    "        SaveImaged(keys=\"pred\", meta_keys=\"pred_meta_dict\", output_dir=\"./out\", output_postfix=\"seg\", resample=False),\n",
    "    ]\n",
    ")"
   ],
   "id": "6273c4ab5d7c4e59",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-24T15:22:57.879631Z",
     "start_time": "2024-04-24T15:22:28.918815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = UNet(\n",
    "    spatial_dims=3,  # 3D 图像分割 - 所以是 3\n",
    "    in_channels=1,  # 输入通道数 \n",
    "    out_channels=3,  # 包括背景 有 3 个类别\n",
    "    channels=(32, 64, 128, 256, 512),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)\n",
    "\n",
    "checkpoint = torch.load(os.path.join(directory, \"best_metric_model.pth\"))\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_data in test_org_loader:\n",
    "        test_inputs = test_data[\"image\"].to(device)\n",
    "        roi_size = (160, 160, 160)\n",
    "        sw_batch_size = 4\n",
    "        test_data[\"pred\"] = sliding_window_inference(test_inputs, roi_size, sw_batch_size, model)\n",
    "        test_data = [post_transforms(i) for i in decollate_batch(test_data)]\n",
    "        \n",
    "        #"
   ],
   "id": "a4b2436afa475f89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-25 01:22:55,912 INFO image_writer.py:197 - writing: out\\case_00210_0000\\case_00210_0000_seg.nii.gz\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5d5aa3ee1005bbea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
